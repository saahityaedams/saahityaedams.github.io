<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>llm on saahityaedams</title>
    <link>https://saahityaedams.github.io/tags/llm/</link>
    <description>Recent content in llm on saahityaedams</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 17 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://saahityaedams.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>My LLM usage pattern</title>
      <link>https://saahityaedams.github.io/posts/ai_ui_ux/</link>
      <pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate>
      
      <guid>https://saahityaedams.github.io/posts/ai_ui_ux/</guid>
      <description>So, this post is mainly for detailing my experience using LLMs (hate the broad usage of the term, but heh) over the last week for writing a ton of code. The main tools I&amp;rsquo;ve been using is Zed (absolutely love this code editor who &amp;rsquo;ve done a great job with their AI integrations) plus Aider (CLI tool for pair programing with an LLM), both free tools. Both configurable to use a variety of LLM models based on the API key provided.</description>
    </item>
    
    <item>
      <title>llm.c rough notes</title>
      <link>https://saahityaedams.github.io/posts/llm_c/</link>
      <pubDate>Thu, 26 Dec 2024 00:00:00 +0000</pubDate>
      
      <guid>https://saahityaedams.github.io/posts/llm_c/</guid>
      <description>I - Getting the defaults working Fix linux-tools broken install with sudo dpkg -i --force-overwrite /var/cache/apt/archives/linux-tools-common_*.deb and then sudo apt --fix-broken install
Get nvcc (CUDA compiler driver) with sudo apt install nvidia-cuda-toolkit
Initial command ./train_gpt2fp32cu doesn&amp;rsquo;t work due to OOM issue.
Decreasing batch size and sequence length doesn&amp;rsquo;t work ./train_gpt2fp32cu -b 1 -t 512
See GPU usage stats with nvidia-smi and sudo fuser -v /dev/nvidia* and kill process using the significant GPU resources with kill -9 &amp;lt;pid&amp;gt;.</description>
    </item>
    
  </channel>
</rss>
