<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Llm on saahityaedams</title>
    <link>https://saahityaedams.github.io/tags/llm/</link>
    <description>Recent content in Llm on saahityaedams</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Sep 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://saahityaedams.github.io/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Coredump</title>
      <link>https://saahityaedams.github.io/posts/ai_coredump/</link>
      <pubDate>Wed, 24 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://saahityaedams.github.io/posts/ai_coredump/</guid>
      <description>&lt;p&gt;&lt;strong&gt;WIP&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;This is a catch-all post expanding on a couple of points about LLMs that I&amp;rsquo;ve been meaning to jot down over the last few months, based on my limited experience working with them and the general sense of AI discourse I get from Twitter. My main goal is condensing these thoughts into some kind of coherent thesis-ramble. These points sound aggressively confident, so please read them critically and with a pinch of salt.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Tampermonkey</title>
      <link>https://saahityaedams.github.io/posts/ai_tampermonkey/</link>
      <pubDate>Mon, 11 Aug 2025 00:00:00 +0000</pubDate>
      <guid>https://saahityaedams.github.io/posts/ai_tampermonkey/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;The below document is a quick 1 pager proposal I wrote for BoomiAI Weekend Hacks.&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h1 id=&#34;ai-tampermonkeying---11th-august-2025&#34;&gt;AI Tampermonkeying - 11th August 2025&lt;/h1&gt;&#xA;&lt;h2 id=&#34;purpose&#34;&gt;Purpose&lt;/h2&gt;&#xA;&lt;p&gt;This documents details a specific AI product idea to &amp;ldquo;home-cook&amp;rdquo;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; enhancements to existing web applications. I request BoomiAI approval to implement this on 30th August at Boomi AI Weekend Hacks BLR :)&lt;/p&gt;&#xA;&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;&#xA;&lt;h3 id=&#34;tampermonkey&#34;&gt;Tampermonkey&lt;/h3&gt;&#xA;&lt;p&gt;Tampermonkey&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; is a cross-platform browser extension with a large userbase (&amp;gt; 10 million folks) that people use to enhance the functionality of their most frequently used webpage. This is done via writing Javascript scripts called userscripts and running it via the browser extension. Tampermonkey also makes it easy to find and install userscripts created by other users, thus letting you access a library of commonly used customisations and enhancements for your favourite web pages.&lt;/p&gt;</description>
    </item>
    <item>
      <title>My LLM usage pattern</title>
      <link>https://saahityaedams.github.io/posts/ai_ui_ux/</link>
      <pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://saahityaedams.github.io/posts/ai_ui_ux/</guid>
      <description>&lt;p&gt;So, this post is mainly for detailing my experience using LLMs (hate the broad usage of the term, but heh) over the last week for writing a ton of code. The main tools I&amp;rsquo;ve been using is Zed (absolutely love this code editor who &amp;rsquo;ve done a great job with their AI integrations) plus Aider (CLI tool for pair programing with an LLM), both free tools. Both configurable to use a variety of LLM models based on the API key provided. I am a fan of Anthropic&amp;rsquo;s Claude 3.5 Sonnet model which I trust to write great code for me. In terms of cost, looking at the API cost in the Anthropic console tells me I have used approx $10 worth of tokens over the past month.&lt;/p&gt;</description>
    </item>
    <item>
      <title>llm.c rough notes</title>
      <link>https://saahityaedams.github.io/posts/2024/llm_c/</link>
      <pubDate>Thu, 26 Dec 2024 00:00:00 +0000</pubDate>
      <guid>https://saahityaedams.github.io/posts/2024/llm_c/</guid>
      <description>&lt;h3 id=&#34;i---getting-the-defaults-working&#34;&gt;I - Getting the defaults working&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Fix linux-tools broken install with &lt;code&gt;sudo dpkg -i --force-overwrite /var/cache/apt/archives/linux-tools-common_*.deb&lt;/code&gt; and then &lt;code&gt;sudo apt --fix-broken install&lt;/code&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Get nvcc (CUDA compiler driver) with &lt;code&gt;sudo apt install nvidia-cuda-toolkit&lt;/code&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Initial command &lt;code&gt;./train_gpt2fp32cu&lt;/code&gt; doesn&amp;rsquo;t work due to OOM issue.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Decreasing batch size and sequence length doesn&amp;rsquo;t work &lt;code&gt;./train_gpt2fp32cu -b 1 -t 512&lt;/code&gt;&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;See GPU usage stats with &lt;code&gt;nvidia-smi&lt;/code&gt; and &lt;code&gt;sudo fuser -v /dev/nvidia*&lt;/code&gt; and kill process using the significant GPU resources with &lt;code&gt;kill -9 &amp;lt;pid&amp;gt;&lt;/code&gt;. In my case, it was ollama.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
