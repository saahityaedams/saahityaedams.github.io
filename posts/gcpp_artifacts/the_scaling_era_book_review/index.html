<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>The Scaling Era Book Review - saahityaedams</title><meta name="viewport" content="width=device-width, initial-scale=1">
	
  <meta itemprop="name" content="The Scaling Era Book Review">
  <meta itemprop="description" content="Dwarkesh’s book - “The Scaling Era” (25th March 2025, Stripe Press) is a delightful oddity. It’s uniquely formatted - mostly as snippets of his podcast episodes related to AI categorized across crucial aspects of LLMs like Safety and Scaling. The book is a superb highlight reel of Dwarkesh’s podcast, reflecting the excellent quality of his show (superb guest quality, discourse quality, intellectual topics, etc.).
The book excels at discussing the not-strictly technical &amp; under-discussed aspects of LLMs like inference scaling, cluster sizes, and impacts of AGI. Dwarkesh has meticulously edited/curated the interviews and referenced important material discussed in his podcasts (references and glossary made up about 50% of the book on my Kindle). The format also excels in bringing readers perspectives from diverse experts in a relaxed conversation format - both AI doomers (like Yudkowsky) and folks with more nuanced opinions (like Gwern).">
  <meta itemprop="datePublished" content="2025-03-29T00:00:00+00:00">
  <meta itemprop="dateModified" content="2025-03-29T00:00:00+00:00">
  <meta itemprop="wordCount" content="427">
  <meta itemprop="keywords" content="Gcpp,Review"><meta property="og:url" content="https://saahityaedams.github.io/posts/gcpp_artifacts/the_scaling_era_book_review/">
  <meta property="og:site_name" content="saahityaedams">
  <meta property="og:title" content="The Scaling Era Book Review">
  <meta property="og:description" content="Dwarkesh’s book - “The Scaling Era” (25th March 2025, Stripe Press) is a delightful oddity. It’s uniquely formatted - mostly as snippets of his podcast episodes related to AI categorized across crucial aspects of LLMs like Safety and Scaling. The book is a superb highlight reel of Dwarkesh’s podcast, reflecting the excellent quality of his show (superb guest quality, discourse quality, intellectual topics, etc.).
The book excels at discussing the not-strictly technical &amp; under-discussed aspects of LLMs like inference scaling, cluster sizes, and impacts of AGI. Dwarkesh has meticulously edited/curated the interviews and referenced important material discussed in his podcasts (references and glossary made up about 50% of the book on my Kindle). The format also excels in bringing readers perspectives from diverse experts in a relaxed conversation format - both AI doomers (like Yudkowsky) and folks with more nuanced opinions (like Gwern).">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-03-29T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-03-29T00:00:00+00:00">
    <meta property="article:tag" content="Gcpp">
    <meta property="article:tag" content="Review">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="The Scaling Era Book Review">
  <meta name="twitter:description" content="Dwarkesh’s book - “The Scaling Era” (25th March 2025, Stripe Press) is a delightful oddity. It’s uniquely formatted - mostly as snippets of his podcast episodes related to AI categorized across crucial aspects of LLMs like Safety and Scaling. The book is a superb highlight reel of Dwarkesh’s podcast, reflecting the excellent quality of his show (superb guest quality, discourse quality, intellectual topics, etc.).
The book excels at discussing the not-strictly technical &amp; under-discussed aspects of LLMs like inference scaling, cluster sizes, and impacts of AGI. Dwarkesh has meticulously edited/curated the interviews and referenced important material discussed in his podcasts (references and glossary made up about 50% of the book on my Kindle). The format also excels in bringing readers perspectives from diverse experts in a relaxed conversation format - both AI doomers (like Yudkowsky) and folks with more nuanced opinions (like Gwern).">
<link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" media="screen" href="https://saahityaedams.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://saahityaedams.github.io/css/main.css" />

        <link id="dark-scheme" rel="stylesheet" type="text/css" href="https://saahityaedams.github.io/css/dark.css" />

	<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
		<script src="https://saahityaedams.github.io/js/main.js"></script>
</head>

<body>
	<div class="container wrapper">
		<div class="header">
	
	<h1 class="site-title"><a href="https://saahityaedams.github.io/">saahityaedams</a></h1>
	<div class="site-description"><p></p><nav class="nav social">
			<ul class="flat"><li><a href="/index.xml" title="RSS"><i data-feather="rss"></i></a></li></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">Home</a>
			</li>
			
			<li>
				<a href="/posts">All posts</a>
			</li>
			
			<li>
				<a href="/about">About</a>
			</li>
			
			<li>
				<a href="/driftlog">Driftlog</a>
			</li>
			
			<li>
				<a href="/tags">Tags</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post">
			<div class="post-header">
				
					<div class="meta">
						<div class="date">
							<span class="day">29</span>
							<span class="rest">Mar 2025</span>
						</div>
					</div>
				
				<div class="matter">
					<h1 class="title">The Scaling Era Book Review</h1>
				</div>
			</div>
					
			<div class="markdown">
				<p>Dwarkesh&rsquo;s book - &ldquo;The Scaling Era&rdquo; (25th March 2025, Stripe Press) is a delightful oddity. It&rsquo;s uniquely formatted - mostly as snippets of his podcast episodes related to AI categorized across crucial aspects of LLMs like Safety and Scaling. The book is a superb highlight reel of Dwarkesh&rsquo;s podcast, reflecting the excellent quality of his show (superb guest quality, discourse quality, intellectual topics, etc.).</p>
<p>The book excels at discussing the not-strictly technical &amp; under-discussed aspects of LLMs like inference scaling, cluster sizes, and impacts of AGI. Dwarkesh has meticulously edited/curated the interviews and referenced important material discussed in his podcasts (references and glossary made up about 50% of the book on my Kindle). The format also excels in bringing readers perspectives from diverse experts in a relaxed conversation format - both AI doomers (like Yudkowsky) and folks with more nuanced opinions (like Gwern).</p>
<p>That said, the book sometimes felt awkward to read. While it&rsquo;s easy reading, without a narrative hook its dialogue structure can feel disjointed and lack continuous flow (inherent to the book&rsquo;s format). On the other hand, this did help me get through it over work breaks last week.</p>
<p>For me, the main takeaway was the reinforcement of AI Scaling laws (larger compute &amp; data -&gt; better AI, more time to think -&gt; better AI). It&rsquo;s interesting how AI Scaling laws are being driven/bottlenecked by factors like economics/power availability rather than purely technical aspects. It&rsquo;s also pretty alarming how none of the experts can precisely say how or why this technology works and how much we are just going by empirical vibes rather than theoretical research. Plus, there&rsquo;s a very thorough discussion about the important societal/public policy implications of AI (obviously from a Western perspective about the first world, but I&rsquo;ll take it).</p>
<p>This book is superb for an AI (or Tech) enthusiast understanding the entire landscape and the important aspects of these systems (especially the societal ones). I love this line from Dwarkesh towards the end of his book which reflects how I feel:</p>
<p><em>&ldquo;The purpose of this book is to capture what it feels like to be in the midst of the scaling era&rdquo;.</em></p>
<p>It really does feel dizzying with what seems like monthly AI breakthroughs non stop, for the past couple of years. Just between this book being written and published (4 months?), we had breakthroughs like reasoning models and DeepSeek come out, which the book understandably skips. Going by the book, I&rsquo;m hunkering down for at least another half a decade more of AI acceleration and restructuring of society.</p>
<p>Rating: 4/5</p>

			</div>

			<div class="tags">
				
					
						<ul class="flat">
							
							<li><a href="/tags/gcpp">gcpp</a></li>
							
							<li><a href="/tags/review">review</a></li>
							
						</ul>
					
				
			</div></div>
	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div>2026  <a href="https://github.com/knadh/hugo-ink">Ink</a> theme on <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>


      <script async src="https://www.googletagmanager.com/gtag/js?id=G-ZY0T40ZV0H"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-ZY0T40ZV0H');
        }
      </script><script>feather.replace()</script>
</body>
</html>
